[{"title":"Imbalance in the Cloud: an Analysis on Alibaba Cluster Trace","date":"2018-03-13T16:07:00.000Z","path":"2018/03/14/Imbalance-in-the-Cloud/","text":"背景：阿里在2017年09月05日首次公布了该数据，trace数据是ClusterData在2017年08月12日小时内生产群集的群集信息，并包含大约1.3k台运行在线服务和批处理作业的机器。链接：https://www.researchgate.net/publication/322512121_Imbalance_in_the_cloud_An_analysis_on_Alibaba_cluster_trace 简介为了提高资源利用率并为云设计智能调度程序，了解大型云数据中心的工作负载特征和机器利用率。在本文中，对2017年9月阿里巴巴新发布的跟踪数据集进行了深入分析，包括11089个在线服务作业的详细统计数据和1295个超过12小时的1300台机器上的12951个批处理作业。这是分析阿里巴巴公布trace数据后的第一份工作之一。分析了关于阿里云不同类型的几点不平衡。这种不平衡加剧了云资源管理的复杂性和挑战性，这可能会导致严重的资源浪费和低集群利用率。 空间失衡：跨机器和工作负载的异构资源利用率。 时间不平衡：每个工作负载和机器的资源使用量随时间变化很大。 每个工作负载的多维资源（CPU和内存）利用率不平衡。 在线服务和脱机批处理作业之间的资源需求和运行时间统计（持续时间和任务编号）不平衡。 文章认为，在资源分配过程中调节这种不平衡对于提高集群效率至关重要，并会激励新资源管理者和调度人员的出现。 数据介绍trace包括数据三种类型，跟踪中有三种类型的数据：批处理和在线服务的不同时刻的工作负载、机器利用率和运行时间信息。 出于机密原因，跟踪中的部分信息被模糊处理。 机器利用率 被描述为两个栏：“机器事件”和“机器资源利用率”。容量反映了每台机器的标准化多维物理容量。每个维度（CPU核心，RAM大小）都是独立标准化的。 批处理工作负载 被描述为两个栏：“实例”和“任务”。 户以Job的形式提交批处理工作负载（不包含在trace中）。每个Job都由多个任务组成，每个任务根据数据依赖性形成一个DAG。它们由多个实例组成，并执行不同的计算逻辑。实例是批处理工作负载的最小调度单位。任务中的所有实例都执行完全相同的多资源需求的二进制代码，但处理不同部分的数据。 在线服务作业 由两个栏描述：“服务实例事件”和“服务实例使用情况”。trace仅包含两种类型的实例事件。一个创建事件，另一个完成。创建事件记录服务实例的起始时间，而移除事件表示服务实例的完成时间。每个实例是最小的调度单元，并在Linux容器（LXC）的轻量级虚拟机中运行。它也可以被视为一项完整的服务工作。 批处理或服务工作负载的任何一个实例都以保留的形式表达其资源需求，这在现代资源管理员中是常用的。他们的Fuxi集群管理员利用资源分配的接纳控制策略。上述两种机制的结合被认为是近期研究中群集利用率低和资源低效的根本原因。 机器使用不均衡的情况图1绘出了12小时内群集中每台计算机的资源利用情况。trace提供了每台机器每个采样时间的标准化CPU和内存使用信息。所有数据都从“机器事件”和“机器资源利用率”表中检索。我一个有趣的观察是，一部分机器（ID从400到600和900到1100）的CPU使用率总是高于其他机器，而他们的内存使用率相对较低。在群集运行期间，大多数机器的CPU利用率正在逐渐增加，同时内存利用率在下降。因此，当观察到跟踪期结束时（从11到12小时）CPU的最高利用率和机器的最低内存利用率。相比之下，CPU在开始时一直处于空闲状态（从0到3.5小时），而内存则保持高负载状态。这表明，云数据中心机器存在显着的空间不平衡（跨机器的资源异构利用）和时间不平衡（每台机器随时间变化的资源使用情况）。从图2中，我们看到每台机器资源使用情况的细粒度信息。我们总结了每台采样时间1300台机器的平均，最小和最大利用率。 CPU和内存使用都被标准化采样周期内，每台机器的平均CPU利用率在40％以内，最高维持在60％左右。每台机器的平均内存利用率在60％以内，最高约为90％。绿线表示每采样时间所有机器中利用率最低的机器利用率。这种最小用途的CPU和内存利用率接近于零。从8小时到10小时，CPU的最大利用率迅速攀升，达到90％以上，而平均CPU利用率保持稳定。通过比较这些机器的最小，平均和最大使用量之间的巨大差距，我们观察到了集群中利用率的巨大空间不平衡。它表明，云数据中心需要新的调度器来平衡负载，避免机器利用的热点，从而提高集群效率。与CPU使用情况不同，内存使用在此期间保持稳定。它还表明工作负载的多维资源利用率（CPU和内存）的比例失衡。此外，我们观察到群集中CPU和内存资源的严重浪费和资源低效率。但是，由于机器的最大使用率相对较低，通过全面了解工作负载的资源需求并进行适当的保留，CPU利用率有机会大大提高。尽管如此，提高内存利用率仍然具有挑战性，因为工作性能对机器相对较高的最高使用率非常敏感。简单地减少保留以提高集群内存效率可能会导致严重的性能下降。最近的研究通过提出更好的需求估计提出了一种解决方案。我们认为，云数据中心需要新的资源管理者和调度人员，通过避免上述不平衡和低利用率来提高集群资源的效率。 工作负载的不均衡资源需求的不均衡 批量工作负载: 大多数批处理作业为每个任务 请求 1到100个CPU核心，而最大请求数量大于1000。相比之下，我们观察到大多数作业使用0.01到1个核心CPU每个任务，而很少 使用 超过100个核心。而大多数任务要求每个实例的规格化内存大小在0.05到0.15之间。虽然他们通常使用0.001到0.05的尺寸。 服务工作负载: 大多数服务实例在执行期间稳定地使用了少于10％的CPU资源。但是，总有一部分实例占用60％到90％的资源，而有些则使用接近零的内核。规范化的平均内存利用率稳定在45％，最大值保持在79％，最小值保持在1％。与CPU的资源不同，它表明有机会做出更好的保留来提高内存利用率。 用户总是倾向于过度配置资源以保证SLA对延迟敏感的生产服务。但是，这种极低的利用率会为大规模云数据中心带来难以置信的高成本。同时，在线服务作业永久保留和保存资源，由于受限主机资源不足，可能会导致集群负载不均（热点）或工作不足。 批量工作负载的不均衡图9绘出了批处理作业的持续时间分布。我们利用同一作业中最早创建的任务和最晚完成的任务的持续时间之间的差异来指示作业运行时间。90％的工作时间少于0.19小时，而最长的工作时间长达10小时。详细地说，超过12481个Job的运行时间不到一个半小时，超过12705个Job的运行时间不到1个小时。短Job压倒性地占据了集群。表明了工作持续时间的不平衡。人们可以考虑这些现象，并利用适当的调度算法，如SJF（最短作业优先）来加速短作业的执行，同时最大化集群完工时间。 一些思考由于阿里云数据中心的预留机制和不平衡的现象，将服务和批量作业放置在相同机器对提高集群效率并不有效。未来，可以利用容器的灵活分配和不平衡知识来显着提高混合集群的资源利用率。另外，通过考虑数据的局限性，在调度过程中不平衡现象会加剧。如何通过适当的资源分配和调度决策来平衡不平衡救济，数据局部性和SLA（性能）之间的权衡是非常具有挑战性的。它也成为我们未来的研究方向。 结论了解大型云数据中心中的机器特征和工作负载行为对于最大限度地提高群集资源效率至关重要。在本文中，对阿里巴巴集团2017年9月新发布的跟踪数据集进行了深入分析，涵盖1300多台服务器，超过12小时。这是分析阿里巴巴公众痕迹的第一份工作之一。文章研究了混部集群的详细运行时特性，该集群可以同时在线服务和脱机批处理作业，并发现了关于云中不平衡的一些有趣见解。这种不平衡加剧了云集群管理的复杂性和挑战性，导致严重的资源低效率。文章认为，适应机器和工作负载的不平衡对于集群效率至关重要，并且会激励新资源管理者和调度者的设计和出现。","tags":[{"name":"论文","slug":"论文","permalink":"http://changzihao.me/tags/论文/"},{"name":"阿里云","slug":"阿里云","permalink":"http://changzihao.me/tags/阿里云/"},{"name":"不均衡","slug":"不均衡","permalink":"http://changzihao.me/tags/不均衡/"},{"name":"利用率","slug":"利用率","permalink":"http://changzihao.me/tags/利用率/"}]},{"title":"qemu运行riscv linux","date":"2018-02-02T12:12:35.000Z","path":"2018/02/02/qemu-run-riscv/","text":"过程：在物理服务器上安装qemu模拟器，模拟器中运行基于riscv指令集编译的linux镜像文件。 工具集合： riscv-qemu（模拟器，可以模拟运行riscv指令集的程序或镜像） riscv-tools（基于riscv指令集的交叉编译工具） riscv-pk（用于包装内核文件vmlinux） busybox(用于给linux镜像安装基本命令，如ls，cat，mv等等) 一、从零开始首先创建一个工作目录叫做$TOP,进入工作目录，并将设定$TOP环境变量 $ mkdir riscv$ cd riscv$ $ export TOP=$(pwd) 二、安装riscv-toolchain1 . 下载交叉编译工具: $ git clone https://github.com/riscv/riscv-tools.git$ cd $TOP/riscv-tools$ git submodule update --init --recursive 2 . 为了编译gcc，我们需要安装一些其他的依赖库，包括 flex, bison, autotools, libmpc, libmpfr, and libgmp. Ubuntu系统可以通过如下命令安装： $ sudo apt-get install autoconf automake autotools-dev curl device-tree-compiler libmpc-dev libmpfr-dev libgmp-dev gawk build-essential bison flex texinfo gperf 3 . 在开始安装之前，需要设置$RISCV,$PATH环境变量，这些环境变量会在整个安装过程中使用: $ export RISCV=$TOP/riscv #将作为所有工具的安装路径 --prefix=$RISCV$ export PATH=$PATH:$RISCV/bin 4 . 安装spike工具: $ ./build-spike-only.sh 5 . 编译 riscv64-unknown-linux-gnu-gcc: $ cd riscv-gnu-toolchain$ ./configure --prefix=$RISCV 这会将riscv64-unknown-linux-gnu-gcc与riscv64-unknown-elf-gcc工具一样安装到$RISCV，同时 $RISCV/bin已经被添加置PATH中，所以上述工具可以直接使用。 最后执行下面的指令，运行build: $ make linux 三、安装riscv-qemu1、安装qemu: $ cd $TOP$ git clone https://github.com/riscv/riscv-qemu.git$ cd riscv-qemu $ git submodule update --init pixman $ mkdir build$ cd build$ ../configure $ make 2、测试qemu的用户模式: $ riscv64-unknown-linux-gnu-gcc hello.c -o hello$ ./riscv64-linux-user/qemu-riscv64 -L $RISCV/sysroot hello 3、测试qemu的镜像模式:启动qemu，载入bbl示例镜像文件，下载地址:bblvmlinuxinitramfs_dynamic $ riscv-qemu/riscv64-softmmu/qemu-system-riscv64 -kernel /home/tank/bblvmlinuxinitramfs_dynamic -nographic 四、编译busybox$ git clone https://github.com/mirror/busybox$ git checkout 1_28_stable$ cd busybox$ make allnoconfig$ make menuconfig #按照需求设定编译选项、交叉编译工具$ make ARCH=riscv menuconfig #设置交叉编译工具、编译选项、inittab等$ make -j8 CONFIG_STATIC=y, listed as “Build BusyBox as a static binary (no shared libs)” in BusyBox Settings → Build Options CONFIG_CROSS_COMPILER_PREFIX=riscv64-unknown-linux-gnu-, listed as “Cross Compiler prefix” in BusyBox Settings → Build Options CONFIG_FEATURE_INSTALLER=y, listed as “Support —install [-s] to install applet links at runtime” in BusyBox Settings → General Configuration CONFIG_INIT=y, listed as “init” in Init utilities CONFIG_ASH=y, listed as “ash” in Shells CONFIG_ASH_JOB_CONTROL=n, listed as “Ash → Job control” in Shells CONFIG_MOUNT=y, listed as “mount” in Linux System Utilities CONFIG_FEATURE_USE_INITTAB=y, listed as “Support reading an inittab file” in Init Utilities 编译完成后会在busybox目录下生成busybox二进制执行文件 五、编译riscv-linux1 . 获取内核代码: $ cd $TOP$ git clone https://github.com/riscv/riscv-linux.git riscv-linux$ cd riscv-linux 2 . 准备一个文件系统初始化文件，命名为initramfs.txt,可以在其中创建任意想要的文件夹文件，如下是我的文件系统样例： dir /dev 755 0 0nod /dev/console 644 0 0 c 5 1nod /dev/null 644 0 0 c 1 3dir /proc 755 0 0dir /bin 755 0 0dir /tmp 755 0 0file /bin/busybox /path/to/your/busybox 755 0 0slink /init /bin/busybox 755 0 0dir /sbin 755 0 0dir /usr 755 0 0dir /usr/bin 755 0 0dir /usr/sbin 755 0 0dir /etc 755 0 0file /etc/inittab /path/to/your/inittab 644 0 0dir /lib 755 0 0 3 . 准备一份初始化表，命名为inittab,放置在内核的/etc目录下，如下是一个简单的inittab样例： ::sysinit:/bin/busybox mount -t proc proc /proc::sysinit:/bin/busybox mount -t tmpfs tmpfs /tmp::sysinit:/bin/busybox mount -o remount,rw /dev/htifblk0 /::sysinit:/bin/busybox --install -s/dev/console::sysinit:-/bin/ash 4 . 下面正式开始编译内核,首先配置编译选项: $ make mrproper #很重要$ make ARCH=riscv defconfig$ make ARCH=riscv menuconfig #设置交叉编译工具、编译选项、initramfs等$ make -j8 ARCH=riscv 如果不执行make mrproper编译内核时可能出现缺少头文件错误 menuconfig : “General setup -&gt; Initial RAM Filesystem…” (CONFIG_BLK_DEV_INITRD=y) menuconfig : “General setup -&gt; Initramfs source files (CONFIG_INITRAMFS_SRC=/path/to/your/initramfs.txt) menuconfig : “General setup -&gt; Cross-compiler tool prefix (CONFIG_CROSS_COMPILER_PREFIX=riscv64-unknown-linux-gnu-) 六、启动qemu运行linux镜像所有准备工作完成，下面开始运行linux镜像1 . 首先需要通过pk工具包中的bbl工具为linux kernel添加boot loader: $ cd &lt;riscv-pk&gt;/build$ rm -rf *$ ../configure --prefix=$RISCV --host=riscv64-unknown-linux-gnu --with-payload=&lt;riscv-linux&gt;/vmlinux$ make bbl 2 . 接下来通过qemu运行上一步中生成的bbl文件: riscv-qemu/riscv64-softmmu/qemu-system-riscv64 -kernel &lt;riscv-pk&gt;/build/bbl -nographic 3 . 接下来你的屏幕上会想RV图像，通过你的制作的linux镜像也会通过qemu运行，因为我们已经在其中添加了busybox工具包，你可以执行例如ls、cd、pwd等指令。通过还可以将自己编写的c语言，g语言的程序通过riscv的工具链进行编译，然后按照样例修改initramfs.txt文件，将编译好的二进制文件加入到内核的文件系统中，然后重新从编译内核开始重新执行一遍上述过程，便可以在内核中运行你自己写的程序。 七、最后最后我想说的是，上述过程是一个非常繁琐的过程，你需要有足够的耐心以及足够运行，首先gcc工具链和内核的编译安装是一个非常费事的过程，不仅如此你还遇到各种各种莫名其妙的问题，其中各个工具链版本的匹配便是一个令人极度头痛的问题.博主足够幸运，在第一次运行上述过程中非常幸运的没有遇到版本不匹配的问题，希望诸位也能如此幸运。 八、最后的最后近期因为各种原因需要重新使用最新版本复现上述过程，耗时近3天遇到了各种各样的问题。最后，在师兄的提示下，选择了sifive公司的集成工具。完成上述工程只需要： $ git clone --recursive https://github.com/sifive/freedom-u-sdk$ cd freedom-u-sdk$ make all$ make qemu 接下来你就会发现，自己之前所做的一切努力在别人看来只不过一个脚本就能解决，并且你不会想到sifive为你移植多少依赖库。。。最后给大家送上一个运行界面图（默认用户名为：root，密码为：sifive）：","tags":[{"name":"riscv","slug":"riscv","permalink":"http://changzihao.me/tags/riscv/"},{"name":"qemu","slug":"qemu","permalink":"http://changzihao.me/tags/qemu/"}]},{"title":"粒子群算法(PSO) Python 实现","date":"2018-02-02T10:28:00.000Z","path":"2018/02/02/粒子群算法-PSO-Python-实现/","text":"一、简介： 粒子群优化算法是一种基于种群寻优的启发式搜索算 法。在1995年由Kennedy 和Eberhart 首先提出来的。 它的主要启发来源于对鸟群群体运动行为的研究。我 们经常可以观察到鸟群表现出来的同步性，虽然每只 鸟的运动行为都是互相独立的，但是在整个鸟群的飞 行过程中却表现出了高度一致性的复杂行为，并且可 以自适应的调整飞行的状态和轨迹。 鸟群具有这样的复杂飞行行为的原因，可能是因为每 只鸟在飞行过程中都遵循了一定的行为规则，并能够 掌握邻域内其它鸟的飞行信息。 二、原理 粒子群优化算法借鉴了这样的思想，每个粒子代表待 求解问题搜索解空间中的一个潜在解，它相当于一只鸟，“飞行信息”包括粒子当前的位置和速度两个状态量。 每个粒子都可以获得其邻域内其它个体的信息，对所 经过的位置进行评价，并根据这些信息和位置速度更 新规则，改变自身的两个状态量，在“飞行”过程中 传递信息和互相学习，去更好地适应环境。 随着这一过程的不断进行，粒子群最终能够找到问题 的近似最优解。 三、构成要素1 . 粒子群 每个粒子对应所求解问题的一个可行解 粒子通过其位置和速度表示 粒子i在第n轮的位置: $x_n^{(i)}$ 粒子i在第n轮的速度: $v_n^{(i)}$ 2 . 记录 $p_{best}^{(i)}$ :粒子𝑖的历史最好位置 $g_{best}$:全局历史最好位置 3 . 计算适应度的函数 适应度:$𝑓(𝑥)$ 四、算法过程描述1 . 初始化 初始化粒子群:每个粒子的位置和速度，即 $x_0^{(i)}$ 和 $v_0^{(i)}$ 初始化$p_{best}^{(i)}$和$g_{best}$ 2 . 循环执行如下三步直至满足结束条件 计算每个粒子的适应度: $f(x_n^{(i)})$ 更新每个粒子历史最好适应度及其相应的位置，更新当前全局最好适 应度及其相应的位置 更新每个粒子的速度和位置 v_{n+1}^{(i)}=w*v_{n}^{(i)}+c_1*r_1*(p_{best}^{(i)}-x_{n}^{(i)})+c_2*r_2*(g_{best}-x_{n}^{(i)})x_{n+1}^{(i)}=x_n^{(i)}+v_{n+1}^{(i)} 上面公式中：i表示粒子编号；n表示时刻，反映在迭代次数上；w是惯性权重，一般设置在0.4&gt;左右；c表示学习因子，一般都取值为2；Xpbest表示的是粒子i的经验，也即是粒子i所到过最佳位置；Xgbest代表的是全局最优粒子的位置；r是0到1之间的随机值。 3 . 算法终止条件 迭代的轮数 最佳位置连续未更新的轮数 适应度函数的值到达预期要求 五、总结1 . 和遗传算法相比 遗传算法强调“适者生存”，不好的个体在竞争中被淘汰; PSO强调“协同合作”，不好的个体通过学习向好 的方向转变。 遗传算法中最好的个体通过产生更多的后代来传播基因; PSO中的最好个体通过吸引其它个体向它靠近来施加影响。 遗传算法的选择概率只与上一代群体相关，而与历史无关，群体的信息变化过程是一个Markov链过程; 而PSO中的个体除了有位置和速度外，还有着过去的历史信息 ($p_{Best}$、$g_{Best}$)。 2 . 优点 易于实现; 可调参数较少; 所需种群或微粒群规模较小;  计算效率高，收敛速度快。 3 . 缺点 和其它演化计算算法类似，不保证收敛到全局最优解 4 . 一种随机优化算法，适用于求解连续解空间的优化问题 六、实现用python实现粒子群算法，求解函数 $f(x)=x^3-5x^2-2x+3$ 在取值范围[-2,5]之间的最小值和最大值 #𝑓(𝑥) =𝑥3−5𝑥2−2𝑥+3#x = [2~5]import randomclass Bird(object): \"\"\" speed:速度 position:位置 fit:适应度 lbestposition:经历的最佳位置 lbestfit:经历的最佳的适应度值 \"\"\" def __init__(self, speed, position, fit, lBestPosition, lBestFit): self.speed = speed self.position = position self.fit = fit self.lBestFit = lBestFit self.lBestPosition = lBestPositionclass PSO(object): \"\"\" fitFunc:适应度函数 birdNum:种群规模 w:惯性权重 c1,c2:个体学习因子，社会学习因子 solutionSpace:解空间，列表类型：[最小值，最大值]\\ positonSpace:更新后解空间的范围，列表类型：[最小值，最大值] stabel:解的稳定次数 max_stable:最佳位置连续未更新的轮数 \"\"\" def __init__(self, fitFunc, birdNum, w, c1, c2, solutionSpace, max_stable): self.fitFunc = fitFunc self.w = w self.c1 = c1 self.c2 = c2 self.birds, self.best = self.initbirds(birdNum, solutionSpace) self.positonSpace = [solutionSpace[0] - c1 *(solutionSpace[1] - solutionSpace[0]), solutionSpace[1] + c2 *(solutionSpace[1] - solutionSpace[0])] self.stable = 0 self.max_stable =max_stable def initbirds(self, size, solutionSpace): birds = [] for i in range(size): position = random.uniform(solutionSpace[0], solutionSpace[1]) speed = 0 fit = self.fitFunc(position) # (self, speed, position, fit, lBestPosition, lBestFit) birds.append(Bird(speed, position, fit, position, fit)) best = birds[0] for bird in birds : if bird.fit &gt; best.fit : best = bird return birds, best def updateBirds(self): for bird in self.birds: # 更新速度 bird.speed = self.w * bird.speed \\ + self.c1 * random.random() * (bird.lBestPosition - bird.position) \\ + self.c2 * random.random() * (self.best.position - bird.position) # 更新位置 bird.position = bird.position + bird.speed # 相对于solutionSpace进行归一化 bird.position = self.normalization(bird.position) # 跟新适应度 bird.fit = self.fitFunc(bird.position) # 查看是否需要更新经验最优 if bird.fit &gt; bird.lBestFit: bird.lBestFit = bird.fit bird.lBestPosition = bird.position def solve(self, maxIter): # 只考虑了最大迭代次数，如需考虑阈值，添加判断语句就好 is_updated = 0 for i in range(maxIter): # 更新粒子 self.updateBirds() for bird in self.birds: # 查看是否需要更新全局最优 if bird.fit &gt; self.best.fit: self.best = bird is_updated = 1 if is_updated : self.stable = 0 else : self.stable +=1 if self.stable &gt;= self.max_stable: return def normalization(self, position): postion =(position - self.positonSpace[0]) \\ / (self.positonSpace[1] - self.positonSpace[0]) postion = postion * (solutionSpace[1] - solutionSpace[0]) postion = postion + solutionSpace[0] return postiondef fx_max_fit(p): return p ** 3 - 5 * p * p - 2 * p + 3def fx_min_fit(p): return -(p ** 3 - 5 * p * p - 2 * p + 3)if __name__ == '__main__': solutionSpace = [-2, 5] #w: 惯性权重 w = 1 #c1, c2: 个体学习因子，社会学习因子 c1 = 2 c2 = 2 #birdNum:种群规模 birdNum = 5 #maxIter 最大迭代次数 maxIter = 10000 # max_stable:最佳位置连续未更新的轮数 max_stable = 5 max = PSO(fx_max_fit, birdNum, w, c1, c2, solutionSpace, 5) min = PSO(fx_min_fit, birdNum, w, c1, c2, solutionSpace, 5) max.solve(maxIter) min.solve(maxIter) print(max.best.lBestPosition) print(min.best.lBestPosition)","tags":[{"name":"PSO","slug":"PSO","permalink":"http://changzihao.me/tags/PSO/"},{"name":"粒子群","slug":"粒子群","permalink":"http://changzihao.me/tags/粒子群/"}]},{"title":"PA 4/5 实验报告","date":"2017-12-17T13:22:37.000Z","path":"2017/12/17/PA-4-5-实验报告/","text":"PA 4/5 实验报告常子豪 changzihao17s@ict.ac.cn 2017/12/17 必答题: 分时多任务的具体过程请结合代码, 解释分页机制和硬件中断是如何支撑仙剑奇侠传和hello程序在我们的计算机系统(Nanos-lite, AM, NEMU)中分时运行的. 答：为了支持分页机制，实验中我们主要做了三部分的修改1.AM部分该部分主要包括_pte_init（初始化内核分页机制）、 _map(虚拟地址到物理地址的映射)、_umake(在堆栈上初始化陷阱帧)、_switch(切换cr3)等，在nexus-am/am/arch/x86-nemu/src/pte.c中涉及的代码均是与硬件相关，是硬件层面支持页表机制的状态维护。2、Nanos-lite部分该部分与分页机会相关的内容主要包括loader（），将文件以页的形式载入内存，并通过_map建立虚拟地址也物理地址的映射。3、Nemu部分该部分对分页自己的支持主要是通过vaddr_write（）、vaddr_read（）在对内存进行读写时进行虚拟地址到物理地址的变换，这是整个分页机制得以真诚运行的关键。 硬件中断机制硬件中断是分时多任务实现的又一关键，而对于我们的实验来说，这关键中的关键便是时钟中断（_EVENT_IRQ_TIME），和内核自陷（_EVENT_TRAP）。通过这样两种中断保证操作系统中分时多任务机制的正常运行。 总得来说，在整个分时多任务机制中，页表机制保证了操作系统的不同的进程按照相同的虚拟地址来对内存进程访问，这使得操作系统能够运行位置无关代码，同时也实现了按需分配内存和突破物理地址的上限。但是上述折现过程也仅仅是实现了多任务机制对内存资源的有效利用，而保证分时多任务的切换则是通过硬件中断机制得以实现。通过时钟中断来保证不同的进程能够根据一定规则相对公平的利用cpu实行，从而在宏观上实现多任务同时进行。 感悟:本次的报告涵盖了pa4、pa5两部分的内容，主要涵盖了分支多任务、页表和浮点机制。在完成pa4、pa5的过程中，恰逢所选操作系统课程也讲解到相应部分，结合linux 0.11与pa不难发现，在现在操作系统的各种版本中分时多任务、页表机制是不可或缺的部分。尽管操作系统中的调度算法千变万化，但是其核心目标就是保证操作系统多个进程能够相对公平的运行，且能够满足用户的需求。而对于内存和文件系统的管理，现代操作系统几乎无一列外全采用分页式管理，可能不同版本操作系统在页表机制的实现上略有差异，但是其核心思想是一致的，对于内存的管理分页机制就是为了满足虚拟地址到物理地址的映射。目前在实际应用中出现的硬件和操作系统的种类可能有成百上千种，我们不可能一一去了解其实现细节，但是只要能够掌握住了他们设计的初衷及其核心思想，无论今后接触哪一种新的硬件和操作系统都能够很快上手。我觉这才是在完成pa实验后真正应该取得的收获。 pa实验到此基本结束，实现pa的过程也是一路跌跌撞撞。总得看来，我觉在整个pa实验中对与我个人来时主要的难点有一下三个： 如何下手，虽然在很多时候在实验指导书中已经指明了应该从哪里开始，但是从一个现在有代码框架去按照自己的思路代码还是有一点难度的，很多时候当我花了很大精力去实现某一个功能时，可能后果头却在无意中发现框架中已经为我们提供了很多课调用的函数。就像nexus-am/am/arch/x86-nemu/include/x86.h中已经给出了很多虚拟地址转换中可能会用到的宏函数，但是因为没有看到，在实验中这些功能大多都是靠自己实现。这个可能还是与自己没有能详细阅读框架有关。 debug ，在完成pa实验之后才深刻的领悟了，代码写完了才只是完成一半，或者一半都不到，而剩下一半是debug。在整个实验中，我遇到各种各样的奇怪的bug，而随着实验的推进，debug的难度也越来越大，影响最深的是在pa4中，实现系统调用时出现了问题，无论如果也找不出操作系统实现中的问题，最终在nemu的rtl操作中找了问题所在，因为没有考虑符号拓展shr在非32位情况下出错。 如何提高代码效率，在运行打字游戏的实验中，需要在对内存进行写操作实现屏幕刷新。我第一次在实现没有考到性能因素按照自己的想法一个复制内容到内存的函数，结果游戏的帧数只有5帧左右，导致游戏根本无法流畅运行，但是后来思考了一下换成了库函数memcpy效率很大提升，帧数直接到达18帧。 回想整个实验，pa给我带来的不仅是对x86指令集、分页机制、系统调用过程的一个深入了解。我觉得更改大的收获是让我了解到整个计算机协同工作的过程（nemu、am、nano-lite）和在一个相对较大的工程中，如何去维护代码结构、可读性、效率以及如果利用现有手段去寻找代码中的bug。最后，我想说，自己写下的bug总有一天会早上门来，让你用百倍的代价去为他买单。所以希望自己以后能够少写bug。","tags":[{"name":"pa","slug":"pa","permalink":"http://changzihao.me/tags/pa/"}]},{"title":"Hello World","date":"2017-11-16T08:35:52.000Z","path":"2017/11/16/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","tags":[{"name":"hexo","slug":"hexo","permalink":"http://changzihao.me/tags/hexo/"}]},{"title":"PA 2/3 实验报告","date":"2017-11-03T13:06:48.000Z","path":"2017/11/03/PA-2-3-实验报告/","text":"PA 2/3 实验报告常子豪 changzihao17s@ict.ac.cn2017/11/03 必答题: 编译与链接在nemu/include/cpu/rtl.h中, 你会看到由static inline开头定义的各种RTL指令函数. 选择其中一个函数, 分别尝试去掉static, 去掉inline或去掉两者, 然后重新进行编译, 你会看到发生错误. 请分别解释为什么会发生这些错误? 你有办法证明你的想法吗? 答:1.去掉inline会出现如下错误 2、去掉static不会出现报错3、去掉static和inline会出现如下错误 首先为了提高代码的效率，对于经常使用的元操作可以通过inline定义的方式避免用函数调用从而提高效率，但是为了其能够复用，我们必须将其定义在头文件中，由于有多个文件包含了rtl.h这个头文件，这边便会导致函数多次定义的问题，同时在所有调用都可以展开的情况下会把函数原型删除。对于上述三种情况，第一种情况是由于prefic.c文件包含了该函数却没有使用而报错，第二种情况不会报错，第三种情况是由于去掉static和inline之后不同的.c文件include rtl.h导致出现了函数重定义。 编译与链接 在nemu/include/common.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问重新编译后的NEMU含有多少个dummy变量的实体? 你是如何得到这个结果的?、答：有78个dummy变量实体，通过grep指令可以计算common.h在nemu/build/obj路径下一共出现77次加上在common.h的1次，一共78次。 添加上题中的代码后, 再在nemu/include/debug.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问此时的NEMU含有多少个dummy变量的实体? 与上题中dummy变量实体数目进行比较, 并解释本题的结果.答：有30个dummy变量实体，通过grep指令可以计算 debug.h在nemu/build/obj路径下一共出现29次加上在debug.h的1次，一共30次。 修改添加的代码, 为两处dummy变量进行初始化:volatile static int dummy = 0; 然后重新编译NEMU. 你发现了什么问题? 为什么之前没有出现这样的问题? (回答完本题后可以删除添加的代码.) 屏幕快照 2017-11-04 14.53.49 在C语言中只声明不初始化是一种弱定义，当声明多个同名同类型的变量时，编译不会报错，但是到了链接阶段，由于全是弱符号，链接器会随便选择一个。但是，有了声明之后就不一样了，这变成了强定义，编译器无法忽略。 了解Makefile 请描述你在nemu目录下敲入make 后, make程序如何组织.c和.h文件, 最终生成可执行文件nemu/build/nemu. (这个问题包括两个方面:Makefile的工作方式和编译链接的过程.) 关于Makefile工作方式的提示: Makefile中使用了变量, 包含文件等特性 Makefile运用并重写了一些implicit rules 在man make中搜索-n选项, 也许会对你有帮助 RTFM 答：首先我们需要在nemu目录中编写一个Makefile文件，当我们执行make指令时，会首先找到名称满足要求的Makefile文件。随后才是执行Makefile文件，分为Makefile工作部分和编译和链接的本分。在Makefile工作的部分，Makefile首先会根据“include”指令把读取工作目录中的文件，处理内建的变量、明确规则和隐含规则，并建立所有目标和依赖之间的依赖关系结构链表。随后make会执行Makefile中的终极目标，根据之前的依赖关系进行一系列的编译工作。在编译和链接过程中，主要目标是围绕最终文件展开，从最终文件开始，make会一次递归的取寻找每一个依赖文件，是否有、是都需要更新，如果没有或者需要更新，make会按照指定的遍历指令和参数对目标文件进行编译生产依赖文件（例如.o），最终有了所有的依赖文件之后再根据定义好的链接规则将所有文件链接在一起最终生成我们的目标文件。 文件读写的具体过程 仙剑奇侠传中有以下行为: 在navy-apps/apps/pal/src/global/global.c的PAL_LoadGame()中通过fread()读取游戏存档 在navy-apps/apps/pal/src/hal/hal.c的redraw()中通过NDL_DrawRect()更新屏幕 请结合代码解释仙剑奇侠传, 库函数, libos, Nanos-lite, AM, NEMU是如何相互协助, 来分别完成游戏存档的读取和屏幕的更新.在navy-apps/apps/pal/src/global/global.c中函数PAL_LoadGame()有一系列加载数据的函数，但是这些加载各类数据的函数最终都会通过调用fread()来实现加载数据。而fread()是在navy-apps/libs/libc/src/stdio/fread.c中实现的c语言库函数,在fread()中会调用定义在navy-apps/libs/libc/src/stdio/fread.c中实现，而fread()通过调用memcpy()读取文件内容（其中文件内容是在fopen()中处理）。而fopen()的实现与下面要介绍的fwrite()十分类似，这里不做详细介绍。 答：在navy-apps/apps/pal/src/hal/hal.c的redraw()中通过NDL_DrawRect()更新屏幕。NDL_DrawRect()在navy-apps/libs/libndl/src/ndl.c中定义，它会调用fwrite()c语言库函数，在navy-apps/libs/libc/src/stdio/fwrite.c实现，通过fwrite() -&gt; __sfvwrite -&gt; _write(),通过这样的路径，调用关系转接到了navy-apps/libs/libos/src/nanos.c系统调用接口，在nanos.c中_write()再次通过宏函数_syscall_(SYS_write, fd, buf,count),这变成功转换到我们实现的中断处理部分，此时_syscall()执行int 0x80参数中断，并设定好相应参数，随后操作系统通过nanos-lite/src/ syscall.c中定义的_RegSet* do_syscall(_RegSet *r)捕获中断，判断出其为SYS_write,然后调用fs_write(),而我们在nanos-lite/src/fs.c中实现读取文件，通过参数fd判断出文件类型为FD_fb继而通过fb_write()更新屏幕。而fb_write()则是调用了之前在nexus-am/am/arch/x86-nemu/src/ioe.c中实现_draw_rect()来在更新显示内容所对用的内存。这便是其完成的技术路径。 总的来看，应用程序的整体流程大致如下：在nanos-lite执行make run，首先程序编译navy-apps路径下我们指定的应用程序，而在编译应用程序时使用的系统调用有关的实现均在navy-apps/libs/下代码中实现，而这边本分代码会通过在nexus-am/am/arch/x86-nemu/src/中定义的与硬件十分相关的代码来实现对硬件的具体读写等操作，最终在应用程序、操作系统、lib、am等完成编译后生成镜像，在交给nemu执行。 感悟:本次的报告涵盖了pa2、pa3两部分的内容，这两部分包含通过int 0x80中断机制将nemu的实现，am实现，操作系统的实现串联起来，环环相扣。在实现中遇到了很多难以找寻的bug，但是这大多与自己思考不够细致有关，而且较多集中在和操作数长度、符号拓展有关，这个两个方面可以说是bug的重灾区，比如push指令的符号拓展，判定SF位时要考虑操作数长度。这里着重要提一下SF设置的问题，这个bug是在成功运行仙剑之后才出现，当时的代码遍及nemu、am、nanos三个部分，寻找错误不易，而且之前在diff_test也没有暴露出来,最后无奈找来正确代码一步一步替换才定位到时rtl_update_SF出现错误，这也算是自己给自己挖下的一个大坑吧。目前关于身边很多同学都经常在之前提到的操作数长度、符号拓展两块出现出错，而且是经常大家遇到同样的错误提示，同样的原因，个人觉得可以在pa的实验指导书适当提醒同学们，让同学少给自己挖坑。","tags":[{"name":"pa","slug":"pa","permalink":"http://changzihao.me/tags/pa/"}]}]